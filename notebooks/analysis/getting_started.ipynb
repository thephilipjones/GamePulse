{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GamePulse Data Analysis - Getting Started\n",
    "\n",
    "This notebook provides an introduction to analyzing GamePulse data, including:\n",
    "- Database connection setup\n",
    "- Data pipeline overview\n",
    "- Social post lifecycle tracking\n",
    "- Match analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sqlmodel import create_engine, Session, text\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "\n",
    "# Build connection string from environment variables\n",
    "DATABASE_URL = (\n",
    "    f\"postgresql+psycopg://{os.environ.get('POSTGRES_USER', 'postgres')}:\"\n",
    "    f\"{os.environ.get('POSTGRES_PASSWORD', 'changethis')}@\"\n",
    "    f\"{os.environ.get('POSTGRES_SERVER', 'db')}:\"\n",
    "    f\"{os.environ.get('POSTGRES_PORT', '5432')}/\"\n",
    "    f\"{os.environ.get('POSTGRES_DB', 'app')}\"\n",
    ")\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "print(f\"Connected to database: {os.environ.get('POSTGRES_DB', 'app')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for running queries\n",
    "def query(sql: str) -> pd.DataFrame:\n",
    "    \"\"\"Execute SQL query and return results as DataFrame.\"\"\"\n",
    "    with Session(engine) as session:\n",
    "        return pd.read_sql(text(sql), session.connection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline Overview\n",
    "\n",
    "GamePulse ingests social media data through this pipeline:\n",
    "```\n",
    "Raw Sources → Staging → Fact Tables\n",
    "─────────────────────────────────────\n",
    "raw_reddit_posts    ↘\n",
    "                     → stg_social_posts → fact_social_sentiment\n",
    "raw_bluesky_posts   ↗\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row counts at each stage of the pipeline\n",
    "pipeline_counts = query(\"\"\"\n",
    "    SELECT 'raw_reddit_posts' as stage, 1 as stage_order, COUNT(*) as row_count\n",
    "    FROM raw_reddit_posts\n",
    "    UNION ALL\n",
    "    SELECT 'raw_bluesky_posts', 2, COUNT(*) FROM raw_bluesky_posts\n",
    "    UNION ALL\n",
    "    SELECT 'stg_social_posts', 3, COUNT(*) FROM stg_social_posts\n",
    "    UNION ALL\n",
    "    SELECT 'fact_social_sentiment', 4, COUNT(*) FROM fact_social_sentiment\n",
    "    ORDER BY stage_order\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Pipeline Row Counts ===\")\n",
    "pipeline_counts[[\"stage\", \"row_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pipeline funnel\n",
    "fig = go.Figure(\n",
    "    go.Funnel(\n",
    "        y=pipeline_counts[\"stage\"],\n",
    "        x=pipeline_counts[\"row_count\"],\n",
    "        textinfo=\"value+percent initial\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(title=\"Social Data Pipeline Funnel\", height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data freshness - when was each table last updated?\n",
    "freshness = query(\"\"\"\n",
    "    SELECT 'raw_reddit_posts' as table_name,\n",
    "           MAX(fetched_at) as last_updated,\n",
    "           COUNT(*) as total_rows,\n",
    "           COUNT(*) FILTER (WHERE fetched_at > NOW() - INTERVAL '1 hour') as last_hour\n",
    "    FROM raw_reddit_posts\n",
    "    UNION ALL\n",
    "    SELECT 'raw_bluesky_posts', MAX(fetched_at), COUNT(*),\n",
    "           COUNT(*) FILTER (WHERE fetched_at > NOW() - INTERVAL '1 hour')\n",
    "    FROM raw_bluesky_posts\n",
    "    UNION ALL\n",
    "    SELECT 'stg_social_posts', MAX(processed_at), COUNT(*),\n",
    "           COUNT(*) FILTER (WHERE processed_at > NOW() - INTERVAL '1 hour')\n",
    "    FROM stg_social_posts\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Data Freshness ===\")\n",
    "freshness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Social Post Lifecycle\n",
    "\n",
    "Track posts through their journey:\n",
    "1. **Ingested**: Raw posts pulled from Reddit/Bluesky\n",
    "2. **Processed**: Posts transformed and staged\n",
    "3. **Matched**: Posts successfully linked to games\n",
    "4. **Discarded**: Posts that couldn't be matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifecycle breakdown by platform\n",
    "lifecycle = query(\"\"\"\n",
    "    WITH raw_counts AS (\n",
    "        SELECT 'reddit' as platform, COUNT(*) as ingested FROM raw_reddit_posts\n",
    "        UNION ALL\n",
    "        SELECT 'bluesky', COUNT(*) FROM raw_bluesky_posts\n",
    "    ),\n",
    "    staged_counts AS (\n",
    "        SELECT platform, COUNT(*) as processed\n",
    "        FROM stg_social_posts\n",
    "        GROUP BY platform\n",
    "    ),\n",
    "    matched_counts AS (\n",
    "        SELECT s.platform, COUNT(*) as matched\n",
    "        FROM fact_social_sentiment f\n",
    "        JOIN stg_social_posts s ON f.social_post_key = s.social_post_key\n",
    "        GROUP BY s.platform\n",
    "    )\n",
    "    SELECT\n",
    "        r.platform,\n",
    "        r.ingested,\n",
    "        COALESCE(s.processed, 0) as processed,\n",
    "        COALESCE(m.matched, 0) as matched,\n",
    "        COALESCE(s.processed, 0) - COALESCE(m.matched, 0) as unmatched\n",
    "    FROM raw_counts r\n",
    "    LEFT JOIN staged_counts s ON r.platform = s.platform\n",
    "    LEFT JOIN matched_counts m ON r.platform = m.platform\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Social Post Lifecycle by Platform ===\")\n",
    "lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate conversion rates\n",
    "if not lifecycle.empty and lifecycle[\"ingested\"].sum() > 0:\n",
    "    total_ingested = lifecycle[\"ingested\"].sum()\n",
    "    total_processed = lifecycle[\"processed\"].sum()\n",
    "    total_matched = lifecycle[\"matched\"].sum()\n",
    "\n",
    "    print(\"=== Conversion Rates ===\")\n",
    "    print(f\"Ingested → Processed: {total_processed / total_ingested * 100:.1f}%\")\n",
    "    if total_processed > 0:\n",
    "        print(f\"Processed → Matched:  {total_matched / total_processed * 100:.1f}%\")\n",
    "    print(f\"Overall (Ingested → Matched): {total_matched / total_ingested * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"No data available yet. Run the Dagster pipelines to ingest data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize lifecycle as stacked bar\n",
    "if not lifecycle.empty and lifecycle[\"ingested\"].sum() > 0:\n",
    "    lifecycle_melted = lifecycle.melt(\n",
    "        id_vars=[\"platform\"],\n",
    "        value_vars=[\"matched\", \"unmatched\"],\n",
    "        var_name=\"status\",\n",
    "        value_name=\"count\",\n",
    "    )\n",
    "\n",
    "    fig = px.bar(\n",
    "        lifecycle_melted,\n",
    "        x=\"platform\",\n",
    "        y=\"count\",\n",
    "        color=\"status\",\n",
    "        title=\"Post Lifecycle: Matched vs Unmatched by Platform\",\n",
    "        color_discrete_map={\"matched\": \"#2ecc71\", \"unmatched\": \"#e74c3c\"},\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Volume Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily ingestion volume (last 30 days)\n",
    "daily_volume = query(\"\"\"\n",
    "    SELECT\n",
    "        DATE(fetched_at) as date,\n",
    "        'reddit' as source,\n",
    "        COUNT(*) as posts\n",
    "    FROM raw_reddit_posts\n",
    "    WHERE fetched_at > NOW() - INTERVAL '30 days'\n",
    "    GROUP BY DATE(fetched_at)\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        DATE(fetched_at),\n",
    "        'bluesky',\n",
    "        COUNT(*)\n",
    "    FROM raw_bluesky_posts\n",
    "    WHERE fetched_at > NOW() - INTERVAL '30 days'\n",
    "    GROUP BY DATE(fetched_at)\n",
    "    ORDER BY date, source\n",
    "\"\"\")\n",
    "\n",
    "if not daily_volume.empty:\n",
    "    fig = px.line(\n",
    "        daily_volume,\n",
    "        x=\"date\",\n",
    "        y=\"posts\",\n",
    "        color=\"source\",\n",
    "        title=\"Daily Ingestion Volume (Last 30 Days)\",\n",
    "        markers=True,\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data in the last 30 days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Match Analysis\n",
    "\n",
    "Analyze how well social posts are matched to games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match rates by subreddit (from raw posts)\n",
    "subreddit_match_rates = query(\"\"\"\n",
    "    SELECT\n",
    "        subreddit,\n",
    "        COUNT(*) as total_posts,\n",
    "        COUNT(*) FILTER (WHERE matched_to_game = true) as matched_posts,\n",
    "        ROUND(COUNT(*) FILTER (WHERE matched_to_game = true)::numeric / COUNT(*) * 100, 1) as match_rate_pct\n",
    "    FROM raw_reddit_posts\n",
    "    GROUP BY subreddit\n",
    "    HAVING COUNT(*) > 10\n",
    "    ORDER BY match_rate_pct DESC\n",
    "\"\"\")\n",
    "\n",
    "if not subreddit_match_rates.empty:\n",
    "    print(\"=== Match Rates by Subreddit ===\")\n",
    "    display(subreddit_match_rates)\n",
    "else:\n",
    "    print(\"No subreddit data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game coverage - how many games have social data?\n",
    "game_coverage = query(\"\"\"\n",
    "    WITH game_post_counts AS (\n",
    "        SELECT\n",
    "            g.game_key,\n",
    "            g.game_date,\n",
    "            COUNT(f.social_post_key) as post_count\n",
    "        FROM fact_game g\n",
    "        LEFT JOIN fact_social_sentiment f ON g.game_key = f.game_key\n",
    "        WHERE g.game_date >= CURRENT_DATE - INTERVAL '30 days'\n",
    "        GROUP BY g.game_key, g.game_date\n",
    "    )\n",
    "    SELECT\n",
    "        COUNT(*) FILTER (WHERE post_count > 0) as games_with_posts,\n",
    "        COUNT(*) FILTER (WHERE post_count = 0) as games_without_posts,\n",
    "        COUNT(*) as total_games,\n",
    "        ROUND(COUNT(*) FILTER (WHERE post_count > 0)::numeric / NULLIF(COUNT(*), 0) * 100, 1) as coverage_pct\n",
    "    FROM game_post_counts\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Game Coverage (Last 30 Days) ===\")\n",
    "game_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dimensional Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams overview\n",
    "teams = query(\"\"\"\n",
    "    SELECT\n",
    "        sport,\n",
    "        COUNT(*) as team_count,\n",
    "        COUNT(*) FILTER (WHERE primary_color IS NOT NULL) as with_colors,\n",
    "        COUNT(*) FILTER (WHERE array_length(aliases, 1) > 0) as with_aliases\n",
    "    FROM dim_team\n",
    "    GROUP BY sport\n",
    "    ORDER BY team_count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Teams by Sport ===\")\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games by sport and status\n",
    "games = query(\"\"\"\n",
    "    SELECT\n",
    "        sport,\n",
    "        COUNT(*) as total_games,\n",
    "        COUNT(*) FILTER (WHERE game_date >= CURRENT_DATE) as upcoming,\n",
    "        COUNT(*) FILTER (WHERE game_date < CURRENT_DATE) as completed\n",
    "    FROM fact_game\n",
    "    GROUP BY sport\n",
    "    ORDER BY total_games DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Games by Sport ===\")\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sentiment Analysis Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "sentiment_dist = query(\"\"\"\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN sentiment_compound >= 0.05 THEN 'positive'\n",
    "            WHEN sentiment_compound <= -0.05 THEN 'negative'\n",
    "            ELSE 'neutral'\n",
    "        END as sentiment,\n",
    "        COUNT(*) as count\n",
    "    FROM fact_social_sentiment\n",
    "    GROUP BY 1\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "if not sentiment_dist.empty:\n",
    "    fig = px.pie(\n",
    "        sentiment_dist,\n",
    "        values=\"count\",\n",
    "        names=\"sentiment\",\n",
    "        title=\"Sentiment Distribution\",\n",
    "        color=\"sentiment\",\n",
    "        color_discrete_map={\n",
    "            \"positive\": \"#2ecc71\",\n",
    "            \"neutral\": \"#95a5a6\",\n",
    "            \"negative\": \"#e74c3c\",\n",
    "        },\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No sentiment data available yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Explore specific games**: Query `fact_game` joined with `fact_social_sentiment`\n",
    "2. **Analyze team performance**: Correlate sentiment with game outcomes\n",
    "3. **Time-series analysis**: Use TimescaleDB functions for time-based aggregations\n",
    "4. **Build dashboards**: Create interactive visualizations with Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings (2025-11-20 Analysis)\n",
    "\n",
    "**✅ Pipeline is Now Working Correctly**\n",
    "\n",
    "The root causes have been fixed:\n",
    "1. ✅ `dim_date` populated (1,461 dates from 2024-2027)\n",
    "2. ✅ `fact_game` populated (37 games today)\n",
    "3. ✅ Team aliases populated (173/173 teams)\n",
    "4. ✅ Transform asset running (576 posts processed)\n",
    "\n",
    "**❌ Why 0 Posts Are in fact_social_sentiment**\n",
    "\n",
    "The pipeline requires posts to mention **BOTH teams from the same matchup**:\n",
    "- Historical posts (March-Nov): Can't match today's games (Nov 20 only)\n",
    "- Today's posts (90 posts): None mention both teams from a single game\n",
    "- Example: Posts mention \"Colgate\" or \"Elon\" individually, not \"Colgate vs Cornell\"\n",
    "\n",
    "**When Matching Will Improve:**\n",
    "\n",
    "- **Post-game threads**: \"Duke defeats UNC 85-78\" → mentions both teams\n",
    "- **High-profile games**: Duke vs UNC, Kansas vs Kentucky get more discussion\n",
    "- **Tournament games**: March Madness threads explicitly name both teams\n",
    "- **Live game threads**: Real-time discussion mentions both teams\n",
    "\n",
    "**Identified Issues to Fix:**\n",
    "\n",
    "1. **False Positives (High Priority)**:\n",
    "   - \"Colgate\" matched from \"College\" in URLs (36 false matches today)\n",
    "   - Fix: Increase threshold 70→75, exclude URL text from matching\n",
    "\n",
    "2. **Overly Strict Matching (Medium Priority)**:\n",
    "   - Requiring exactly 2 teams excludes valid single-team posts\n",
    "   - Consider: Allow 1-team posts within ±3 hours of game time\n",
    "\n",
    "3. **Date Mismatch (Expected Behavior)**:\n",
    "   - Historical posts can't match today's games\n",
    "   - Solution: Wait for new posts as season progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC 2: Date alignment and matching funnel\n",
    "date_and_matching = query(\"\"\"\n",
    "    SELECT\n",
    "        'Posts (with teams)' as category,\n",
    "        COUNT(*)::text as count,\n",
    "        MIN(created_at::date)::text as earliest,\n",
    "        MAX(created_at::date)::text as latest\n",
    "    FROM stg_social_posts\n",
    "    WHERE matched_to_game = true\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Games (available)',\n",
    "        COUNT(*)::text,\n",
    "        MIN(game_date::date)::text,\n",
    "        MAX(game_date::date)::text\n",
    "    FROM fact_game WHERE sport = 'ncaam'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Posts (today)',\n",
    "        COUNT(*)::text,\n",
    "        CURRENT_DATE::text,\n",
    "        CURRENT_DATE::text\n",
    "    FROM stg_social_posts\n",
    "    WHERE created_at::date = CURRENT_DATE AND matched_to_game = true\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Posts (today, 2 teams)',\n",
    "        COUNT(*)::text,\n",
    "        NULL,\n",
    "        NULL\n",
    "    FROM stg_social_posts\n",
    "    WHERE created_at::date = CURRENT_DATE\n",
    "      AND matched_to_game = true\n",
    "      AND array_length(matched_teams, 1) = 2\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Date Alignment & Matching Funnel ===\")\n",
    "print(\"Posts and games must overlap in date for matching to work.\")\n",
    "print(\"Posts must mention EXACTLY 2 teams to match a specific game.\")\n",
    "date_and_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC 1: Check pipeline infrastructure\n",
    "diagnostic_infrastructure = query(\"\"\"\n",
    "    SELECT\n",
    "        'dim_date populated' as check_name,\n",
    "        CASE WHEN COUNT(*) > 0 THEN '✅ PASS' ELSE '❌ FAIL' END as status,\n",
    "        COUNT(*)::text || ' dates' as details\n",
    "    FROM dim_date\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Teams have aliases',\n",
    "        CASE WHEN COUNT(*) = SUM(CASE WHEN array_length(aliases, 1) > 0 THEN 1 ELSE 0 END)\n",
    "             THEN '✅ PASS' ELSE '⚠️  PARTIAL' END,\n",
    "        SUM(CASE WHEN array_length(aliases, 1) > 0 THEN 1 ELSE 0 END)::text || ' / ' || COUNT(*)::text\n",
    "    FROM dim_team WHERE sport = 'ncaam' AND is_current = true\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Games ingested',\n",
    "        CASE WHEN COUNT(*) > 0 THEN '✅ PASS' ELSE '❌ FAIL' END,\n",
    "        COUNT(*)::text || ' games'\n",
    "    FROM fact_game WHERE sport = 'ncaam'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'Transform asset running',\n",
    "        CASE WHEN COUNT(*) > 0 THEN '✅ PASS' ELSE '❌ FAIL' END,\n",
    "        COUNT(*)::text || ' posts'\n",
    "    FROM stg_social_posts\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Infrastructure Health Checks ===\")\n",
    "diagnostic_infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pipeline Diagnostics & Troubleshooting\n",
    "\n",
    "### Understanding Why Posts Aren't Matching to Games\n",
    "\n",
    "The matching pipeline requires **THREE conditions** to be met:\n",
    "1. ✅ Posts must be matched to teams (via fuzzy text matching)\n",
    "2. ✅ Games must exist in fact_game for the post date\n",
    "3. ✅ Post must mention **BOTH teams** from the same matchup\n",
    "\n",
    "This section helps diagnose which condition is failing."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
